{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "86310e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "with open(\"jive.txt\", \"r\") as f:\n",
    "    data = [[value.strip() for value in line.split(',')] for line in f]\n",
    "\n",
    "df = pl.DataFrame(data, schema=['yob', 'sob', 'qob', 'educ', 'lwage'], orient=\"row\")\n",
    "\n",
    "df = df.slice(1).with_columns(pl.all().cast(pl.Float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e629351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (329_509, 7)\n",
      "┌──────┬──────┬─────┬──────┬──────────┬──────┬────────────┐\n",
      "│ yob  ┆ sob  ┆ qob ┆ educ ┆ lwage    ┆ age  ┆ wage       │\n",
      "│ ---  ┆ ---  ┆ --- ┆ ---  ┆ ---      ┆ ---  ┆ ---        │\n",
      "│ f64  ┆ f64  ┆ f64 ┆ f64  ┆ f64      ┆ f64  ┆ f64        │\n",
      "╞══════╪══════╪═════╪══════╪══════════╪══════╪════════════╡\n",
      "│ 30.0 ┆ 45.0 ┆ 1.0 ┆ 12.0 ┆ 5.790019 ┆ 60.0 ┆ 327.019238 │\n",
      "│ 30.0 ┆ 45.0 ┆ 1.0 ┆ 11.0 ┆ 5.952494 ┆ 60.0 ┆ 384.711614 │\n",
      "│ 30.0 ┆ 45.0 ┆ 1.0 ┆ 12.0 ┆ 5.315949 ┆ 60.0 ┆ 203.557598 │\n",
      "│ 30.0 ┆ 45.0 ┆ 1.0 ┆ 12.0 ┆ 5.595926 ┆ 60.0 ┆ 269.326931 │\n",
      "│ 30.0 ┆ 37.0 ┆ 1.0 ┆ 12.0 ┆ 6.068915 ┆ 60.0 ┆ 432.211478 │\n",
      "│ …    ┆ …    ┆ …   ┆ …    ┆ …        ┆ …    ┆ …          │\n",
      "│ 39.0 ┆ 9.0  ┆ 4.0 ┆ 16.0 ┆ 6.32398  ┆ 51.0 ┆ 557.788579 │\n",
      "│ 39.0 ┆ 34.0 ┆ 4.0 ┆ 15.0 ┆ 5.847161 ┆ 51.0 ┆ 346.24998  │\n",
      "│ 39.0 ┆ 34.0 ┆ 4.0 ┆ 12.0 ┆ 5.909597 ┆ 51.0 ┆ 368.557597 │\n",
      "│ 39.0 ┆ 25.0 ┆ 4.0 ┆ 5.0  ┆ 6.047781 ┆ 51.0 ┆ 423.172967 │\n",
      "│ 39.0 ┆ 36.0 ┆ 4.0 ┆ 19.0 ┆ 5.766817 ┆ 51.0 ┆ 319.519083 │\n",
      "└──────┴──────┴─────┴──────┴──────────┴──────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "    (90 - pl.col(\"yob\")).alias(\"age\"),\n",
    "    pl.col('lwage').exp().alias('wage')\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37907687",
   "metadata": {},
   "source": [
    "# 1 (a) Estimate simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e2441a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.117\n",
      "Method:                 Least Squares   F-statistic:                 4.378e+04\n",
      "Date:                Tue, 18 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        11:47:00   Log-Likelihood:            -3.1935e+05\n",
      "No. Observations:              329509   AIC:                         6.387e+05\n",
      "Df Residuals:                  329507   BIC:                         6.387e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.9952      0.004   1118.882      0.000       4.986       5.004\n",
      "educ           0.0709      0.000    209.243      0.000       0.070       0.072\n",
      "==============================================================================\n",
      "Omnibus:                   191064.440   Durbin-Watson:                   1.870\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4082110.369\n",
      "Skew:                          -2.377   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.575   Cond. No.                         53.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Y = df['lwage'].to_pandas()\n",
    "X = sm.add_constant(df['educ'].to_pandas())\n",
    "\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d328e",
   "metadata": {},
   "source": [
    "# 1 (b & c) Calculating standard errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b7c8c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error for educ: 0.00033860679465786054\n",
      "Clustered Standard Error for educ: [0.03065749 0.00176571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cemkozan\\AppData\\Local\\Temp\\ipykernel_6608\\1258157669.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  standard_error = results.bse[1]\n"
     ]
    }
   ],
   "source": [
    "standard_error = results.bse[1]\n",
    "print(f\"Standard Error for educ: {standard_error}\")\n",
    "\n",
    "clustered_se = results.get_robustcov_results(cov_type='cluster', groups=df['sob'].to_pandas()).bse\n",
    "print(f\"Clustered Standard Error for educ: {clustered_se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d4afc519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003386057670456429\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of OLS standard error\n",
    "\n",
    "N = len(df)\n",
    "residuals_i = results.resid.to_numpy()\n",
    "X_i = X['educ'].to_numpy()\n",
    "X_bar = X_i.mean()\n",
    "\n",
    "homoskedastic_se = np.sqrt((1/N) * sum((residuals_i)**2) / (sum((X_i - X_bar)**2)))\n",
    "\n",
    "print(homoskedastic_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "315432d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Calculated Clustered Standard Error for educ: [0.03065754 0.00176571]\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of clustered standard error\n",
    "\n",
    "P = X.shape[1]\n",
    "Omega = np.zeros((P, P))\n",
    "\n",
    "n_clusters = df['sob'].to_pandas().nunique()\n",
    "clusters = df['sob'].to_pandas().unique()\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    mask = df['sob'].to_pandas() == cluster\n",
    "    e_c = results.resid[mask].to_numpy()\n",
    "    X_c = X[mask].to_numpy()\n",
    "\n",
    "    score_c = X_c.T @ e_c\n",
    "    \n",
    "    cluster_matrix = np.outer(score_c, score_c)\n",
    "\n",
    "    Omega += cluster_matrix\n",
    "\n",
    "\n",
    "correction_factor = (N / (N - P)) * (n_clusters / (n_clusters - 1))\n",
    "\n",
    "Omega *= correction_factor\n",
    "\n",
    "XTX_inv = np.linalg.inv(X.T @ X)\n",
    "clustered_se_manual = np.sqrt(np.diag(XTX_inv @ Omega @ XTX_inv))\n",
    "\n",
    "print(f\"Manually Calculated Clustered Standard Error for educ: {clustered_se_manual}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae530b",
   "metadata": {},
   "source": [
    "# 1 (d) Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "526ce598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap OLS Standard Error for educ: 0.0003356398204111961\n"
     ]
    }
   ],
   "source": [
    "# Estimating OLS standard error by using the bayesian bootstrap:\n",
    "B = 10000\n",
    "\n",
    "# Take the residuals from the previous OLS regression\n",
    "residuals = results.resid.to_numpy()\n",
    "\n",
    "betas = []\n",
    "\n",
    "for b in range(B):\n",
    "    # Resample the residuals with replacement\n",
    "    resampled_residuals = np.random.choice(residuals, size=N, replace=True)\n",
    "\n",
    "    # Create the bootstrap sample\n",
    "    X_boot = X.to_numpy()\n",
    "    y_boot = X_boot @ results.params + resampled_residuals\n",
    "\n",
    "    model_boot = sm.OLS(y_boot, X_boot)\n",
    "    results_boot = model_boot.fit()\n",
    "    beta_boot = results_boot.params[1]\n",
    "\n",
    "    betas.append(beta_boot)\n",
    "\n",
    "bootstrap_ols_se = np.sqrt((1/(B-1)) * sum((betas - np.mean(betas))**2))\n",
    "\n",
    "print(f\"Bootstrap OLS Standard Error for educ: {bootstrap_ols_se}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "83c0c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Clustered Standard Error for educ: 0.0017811296436398563\n"
     ]
    }
   ],
   "source": [
    "# Estimating clustered standard errors by bootstrapping:\n",
    "B = 10000\n",
    "\n",
    "betas = []\n",
    "\n",
    "for b in range(B):\n",
    "    # Resample the clusters themselves:\n",
    "    sampled_clusters = np.random.choice(clusters, size=n_clusters, replace=True)\n",
    "\n",
    "    sample_df = []\n",
    "\n",
    "    for cluster in sampled_clusters:\n",
    "        # Get observations in cluster, then resample them:\n",
    "\n",
    "        cluster_data = df.filter(pl.col(\"sob\") == cluster)\n",
    "        resampled_cluster_data = cluster_data.sample(n=len(cluster_data), with_replacement=True)\n",
    "        sample_df.append(resampled_cluster_data)\n",
    "\n",
    "    # Recalculate the OLS estimate for this bootstrap sample\n",
    "    sample_df = pl.concat(sample_df)\n",
    "    X_boot = sm.add_constant(sample_df['educ'].to_numpy())\n",
    "    y_boot = sample_df['lwage'].to_numpy()\n",
    "\n",
    "    model_boot = sm.OLS(y_boot, X_boot)\n",
    "    results_boot = model_boot.fit()\n",
    "    beta_boot = results_boot.params[1]\n",
    "\n",
    "    betas.append(beta_boot)\n",
    "\n",
    "bootstrap_cluster_se = np.sqrt((1/(B-1)) * sum((betas - np.mean(betas))**2))\n",
    "\n",
    "print(f\"Bootstrap Clustered Standard Error for educ: {bootstrap_cluster_se}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c972d",
   "metadata": {},
   "source": [
    "# 1 (e) Estimate Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d3d61de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                 2.312e+04\n",
      "Date:                Tue, 18 Nov 2025   Prob (F-statistic):               0.00\n",
      "Time:                        12:12:28   Log-Likelihood:            -3.1827e+05\n",
      "No. Observations:              329509   AIC:                         6.365e+05\n",
      "Df Residuals:                  329506   BIC:                         6.366e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              4.1542      0.019    223.239      0.000       4.118       4.191\n",
      "educ               0.0671      0.000    193.403      0.000       0.066       0.068\n",
      "state_avg_educ     0.0696      0.001     46.541      0.000       0.067       0.073\n",
      "==============================================================================\n",
      "Omnibus:                   192038.213   Durbin-Watson:                   1.886\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4171580.656\n",
      "Skew:                          -2.389   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.764   Cond. No.                         308.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to the dataframe with the average years of education for all individuals from the same state\n",
    "df_with_state_avg = df.with_columns(\n",
    "    df.group_by(\"sob\").agg(pl.col(\"educ\").mean().alias(\"state_avg_educ\")).join(df.select(\"sob\"), on=\"sob\")[\"state_avg_educ\"]\n",
    ")\n",
    "\n",
    "# Create X matrix with constant, education, and state average education\n",
    "X_adj = sm.add_constant(df_with_state_avg.select(['educ', 'state_avg_educ']).to_pandas())\n",
    "\n",
    "# Fit the model\n",
    "model_adj = sm.OLS(Y, X_adj)\n",
    "results_adj = model_adj.fit()\n",
    "\n",
    "print(results_adj.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790a446",
   "metadata": {},
   "source": [
    "# 1 (f & g) Calculate standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cb401745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error for educ (adjusted): const             0.018609\n",
      "educ              0.000347\n",
      "state_avg_educ    0.001495\n",
      "dtype: float64\n",
      "Clustered Standard Error for educ (adjusted): [0.1579015  0.00135076 0.0119502 ]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the errors using off-the-shelf package for sanity check\n",
    "standard_error_adj = results_adj.bse\n",
    "print(f\"Standard Error for educ (adjusted): {standard_error_adj}\")\n",
    "\n",
    "clustered_se_adj = results_adj.get_robustcov_results(cov_type='cluster', groups=df_with_state_avg['sob'].to_pandas()).bse\n",
    "print(f\"Clustered Standard Error for educ (adjusted): {clustered_se_adj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3f573e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003374982597896972\n",
      "0.0014546523790667121\n"
     ]
    }
   ],
   "source": [
    "# Calculate the OLS standard error manually for the new model\n",
    "\n",
    "N = len(df)\n",
    "residuals_i = results_adj.resid.to_numpy()\n",
    "\n",
    "X_educ = X_adj['educ'].to_numpy()\n",
    "X_bar = X_educ.mean()\n",
    "\n",
    "educ_homoskedastic_se = np.sqrt((1/N) * sum((residuals_i)**2) / (sum((X_educ - X_bar)**2)))\n",
    "\n",
    "X_avgeduc = X_adj['state_avg_educ'].to_numpy()\n",
    "X_bar = X_avgeduc.mean()\n",
    "\n",
    "avgeduc_homoskedastic_se = np.sqrt((1/N) * sum((residuals_i)**2) / (sum((X_avgeduc - X_bar)**2)))\n",
    "\n",
    "print(educ_homoskedastic_se)\n",
    "print(avgeduc_homoskedastic_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5652a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Calculated Clustered Standard Error for educ: [0.15790174 0.00135076 0.01195022]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the clustered standard error manually for the new model\n",
    "\n",
    "P = X_adj.shape[1]\n",
    "Omega = np.zeros((P, P))\n",
    "\n",
    "n_clusters = df['sob'].to_pandas().nunique()\n",
    "clusters = df['sob'].to_pandas().unique()\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    mask = df['sob'].to_pandas() == cluster\n",
    "    e_c = results_adj.resid[mask].to_numpy()\n",
    "    X_c = X_adj[mask].to_numpy()\n",
    "\n",
    "    score_c = X_c.T @ e_c\n",
    "    \n",
    "    cluster_matrix = np.outer(score_c, score_c)\n",
    "\n",
    "    Omega += cluster_matrix\n",
    "\n",
    "\n",
    "correction_factor = (N / (N - P)) * (n_clusters / (n_clusters - 1))\n",
    "\n",
    "Omega *= correction_factor\n",
    "\n",
    "XTX_inv = np.linalg.inv(X_adj.T @ X_adj)\n",
    "clustered_se_manual = np.sqrt(np.diag(XTX_inv @ Omega @ XTX_inv))\n",
    "\n",
    "print(f\"Manually Calculated Clustered Standard Error for educ: {clustered_se_manual}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2268249",
   "metadata": {},
   "source": [
    "# 1 (h) Bootstrapping errors for new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b5bdbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap OLS Standard Errors: [0.01858613 0.0003446  0.00149249]\n",
      "  Intercept: 0.01858613259405111\n",
      "  Education: 0.0003445970650184384\n",
      "  State Avg Education: 0.001492488201572065\n"
     ]
    }
   ],
   "source": [
    "# Estimating OLS standard error by using the bayesian bootstrap:\n",
    "B = 10000\n",
    "\n",
    "# Take the residuals from the previous OLS regression\n",
    "residuals = results_adj.resid.to_numpy()\n",
    "\n",
    "betas = []\n",
    "\n",
    "for b in range(B):\n",
    "    # Resample the residuals with replacement\n",
    "    resampled_residuals = np.random.choice(residuals, size=N, replace=True)\n",
    "\n",
    "    # Create the bootstrap sample\n",
    "    X_boot = X_adj.to_numpy()\n",
    "    y_boot = X_boot @ results_adj.params + resampled_residuals\n",
    "\n",
    "    model_boot = sm.OLS(y_boot, X_boot)\n",
    "    results_boot = model_boot.fit()\n",
    "    beta_boot = results_boot.params\n",
    "\n",
    "    betas.append(beta_boot)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "betas = np.array(betas)\n",
    "\n",
    "# Calculate standard error for each coefficient\n",
    "bootstrap_ols_se = np.sqrt((1/(B-1)) * np.sum((betas - np.mean(betas, axis=0))**2, axis=0))\n",
    "\n",
    "print(f\"Bootstrap OLS Standard Errors: {bootstrap_ols_se}\")\n",
    "print(f\"  Intercept: {bootstrap_ols_se[0]}\")\n",
    "print(f\"  Education: {bootstrap_ols_se[1]}\")\n",
    "print(f\"  State Avg Education: {bootstrap_ols_se[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "06e9589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap OLS Standard Errors: [0.16124026 0.00137655 0.01222214]\n",
      "  Intercept: 0.16124025970780442\n",
      "  Education: 0.0013765547067013898\n",
      "  State Avg Education: 0.012222135938806456\n"
     ]
    }
   ],
   "source": [
    "# Estimating clustered standard errors by bootstrapping:\n",
    "B = 10000\n",
    "\n",
    "betas = []\n",
    "\n",
    "for b in range(B):\n",
    "    # Resample the clusters themselves:\n",
    "    sampled_clusters = np.random.choice(clusters, size=n_clusters, replace=True)\n",
    "\n",
    "    sample_df = []\n",
    "\n",
    "    for cluster in sampled_clusters:\n",
    "        # Get observations in cluster, then resample them:\n",
    "\n",
    "        cluster_data = df_with_state_avg.filter(pl.col(\"sob\") == cluster)\n",
    "        resampled_cluster_data = cluster_data.sample(n=len(cluster_data), with_replacement=True)\n",
    "        sample_df.append(resampled_cluster_data)\n",
    "\n",
    "    # Recalculate the OLS estimate for this bootstrap sample\n",
    "    sample_df = pl.concat(sample_df)\n",
    "    X_boot = sm.add_constant(sample_df['educ', 'state_avg_educ'].to_numpy())\n",
    "    y_boot = sample_df['lwage'].to_numpy()\n",
    "\n",
    "    model_boot = sm.OLS(y_boot, X_boot)\n",
    "    results_boot = model_boot.fit()\n",
    "    beta_boot = results_boot.params\n",
    "\n",
    "    betas.append(beta_boot)\n",
    "\n",
    "# Calculate standard error for each coefficient\n",
    "bootstrap_cluster_se = np.sqrt((1/(B-1)) * np.sum((betas - np.mean(betas, axis=0))**2, axis=0))\n",
    "\n",
    "print(f\"Bootstrap OLS Standard Errors: {bootstrap_cluster_se}\")\n",
    "print(f\"  Intercept: {bootstrap_cluster_se[0]}\")\n",
    "print(f\"  Education: {bootstrap_cluster_se[1]}\")\n",
    "print(f\"  State Avg Education: {bootstrap_cluster_se[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
